# -*- mode: org -*-
#+title: cpp and modern cpp notes
#+SETUPFILE: ~/set-up-files/basic-setups.org
#+TAGS: Cpp C++

* UML, and engineering design
  + UML notation ::
    - visibility :: + Public - Private # Protected ~ Package
    - relations ::
      + associations :: two objects are linked (directly, or indirectely), chose one which will implement a public function, and the other linked to it will contain the object as private and 'friend' the former.
      + realisation/implementation :: when interface is implement
      + dependency :: indicates that a change to one class, the supplier, might cause a change in the other class, the consumer. The supplier is independent because a change in the consumer does not affect the supplier.
	- 
      + aggregation :: special case of an association meaning “consists of”:
	- eg :: student has many teachers
	- if container dies, content doesn't die with it :: eg : if
          teachers leaves, his students stay
	- implementation :: 'super object' (professor here) has a list of reference to 'sub' object (class)
      + generalisation :: process of extracting shared characteristics from two or more classes, and combining them into a generalized superclass.
	- whereas *specialization* :: creating new subclasses from an existing class, eg : in inheriting subclasses, add more characteristics from superclasses
      + composition :: special case of association, xstrong aggregation,  represents a whole–part relationship and is a form of aggregation. A composition association relationship specifies that the lifetime of the part classifier is dependent on the lifetime of the whole classifier.
	- in a composition association relationship, data usually flows in only one direction (that is, from the whole classifier to the part classifier).
	- eg : composition association relationship connects a Student class with a Schedule class, which means that if you remove the student, the schedule is also removed.

* Notes
[2024-03-02 Sat 02:37]
- vtables :: virtual method tables
  + whenever a class defines a virtual function/method, most compilers add a hidden member variable to the class that points to an array of pointers to (virtual) functions called the ==virtual method table==. These pointers are used at runtime to invoke the appropriate function implementations, because at compile time it may not yet be known if the base function is to be called or a derived one implemented by a class that inherits from the base class. 
  + vtables are the most common implementation of polymorphism in C++
  + when vtables are used, every polymorphic class has a vtable somewhere in the program; you can think of it as a (hidden) *static* data member of the class. Every object of a polymorphic class is associated with the vtable for its most-derived class. By checking this association, the program can work its polymorphic magic.
    - a vtable is an implementation detail, it is not mandated by the C++ standard, but most (all?) C++ compilers use vtables to implement polymorphic behaviour. Compilers are allowed to deviate from this however.
* Topics
- operator overloading (c++98) ::
- call operator (c++98) ::
- braced initialization (c++11) ::
- direct initialization of member functions (c++98) ::
- initializer_list (c++11) :: 
- "compiler magic" ::
- compilation model :: 
- reference members (c++98) ::
- 'auto' return type deduction (c++14) ::
- constexpr (c++11) ::
- lambdas (c++11) ::
  + immediately invoked lambdas (c++11) ::
  + recursive lambdas (c++23) :: 
- attributes on parameters (c++11) ::
- pass by value vs by reference (c++98) ::
- implicit conversion (c++98) ::
- function pointers (c++98) ::
- static member functions (c++98) ::
- non-const member functions (c++98) ::
- deducing 'this' (c++23) :: 
- using aliases (c++11) ::
- efficiency when chaining functions ::
- preprocessor :: 
- templates (c++98) ::
- template argument type deduction (c++98) ::
- alias templates (c++11) ::
- variable templates :: 
- templates instantiations (c++98) ::
- 'noexcept' (c++11) ::
- 'noexcept' in the type system (c++17) ::
- functions attributes (c++11) ::
- variadic templates (c++11) ::
- variadic lambdas (c++14) ::
- integer sequences (c++11) ::
- variadic 'sizeof...()' operator (c++11) :: 
- fold expressions (c++17) ::
- variadic 'using' declarations (c++17) :: 
- non type template parameters (c++98) ::
- template parameter pattern matching (c++11) ::
- explicit lambda templates (c++17) ::
- class template argument deduction (c++17/c++20) ::
- deduction guides (c++17) :: 
- algorithms and stl (c++11) ::
- ranges (c++20) ::
- '<functional>' (c++11) ::
- type_traits :: 
- 'mutable' keyword (c++98) ::
- members copies (c++98) ::
- trivially copiable types (c++98) :: 
- return value optimization (c++98) ::
- guaranteed return value optimization (c++17) ::
- object layouts (c++98) ::
- member padding (c++98) ::
- order of construction/destruction (c++98) ::
- scoping/lookup rules (c++98) ::
- higher order functions ::
- function hiding (c++98) :: 
- concepts, custom concepts (c++20) ::
- tuples and unpacking of tuples (c++11) :: 
- virtual member functions (c++98) ::
- member function pointers (c++98) :: 
- special member functions (c++98/11) :: 
- member function call syntax (c++98) ::
- type erasure (c++98) ::
- three-way comparison operator (operator '<=>') :: 
- dynamic vs automatic storage (c++98) ::
- project structure and layout (design part ??) :: 
- coroutines (design ??) ::
- modules (design ??) :: 
- ODR violations ::

* Assembler
** Sources
- cheatsheet :: https://cs.brown.edu/courses/cs033/docs/guides/x64_cheatsheet.pdf
- cppcon2021, "Just Enough Assembly for Compiler Explorer" :: https://www.youtube.com/watch?v=_sSFtJwgVYQ
** Notes
- compiling to machine code general process :: lexical analysis -> syntax analysis -> semantic analysis -> intermediate code generation -> code optimization -> target code generation
- c++ code source compiling process ::
  + source code -(preprocessor)-> expanded code -(compiler)-> assembly code -(assembler)-> object code (+other object files, and libraries) -(linker)-> executable code
  + preprocessor :: instructions that start with ==#== (#include, #define, #ifdef, etc.), are usually completed in the pre-processing stage: opens all quoted header files, replace all the macros, remove comments, remove from conditional compilation the parts that don't meet the conditions defined in the #ifdefs
    - with gcc, can provide flag ==-E== to stop process to the pre-processing stage (to stop after the preprocessing stage, and do not run the compiler)
  + compiler :: check program for any lexical/grammatical/semantic errors; and generate assembly code. Assembly language only uses some machine language based mnemonics.
    - gcc option ==-S== to stop after compilation proper, and do not assemble
  + assembly :: convert the assembly code generated by the compiler into executable (machine language that can be executed by the machine).
    - gcc ==-c== to assemble assembly code into object code, but not link
  + linker :: system program needed to bind generated binary/object code (and libraries; such as windows' dll (dynamic-link library)) and combine them into an executable, library, or another object file
    - usually, a computer program do not need to be contained within a single object file. In such case, its parts/modules refer to each other using ==symbols== as addresses into other modules, which are mapped into memory addresses when linked for execution. The process of linking is meant to combine these independent parts. The advantage of separating those parts are, among others, ease of organizing several smaller pieces, and the ability to better define the purpose and responsibilities of each individual piece (scalability and maintenance)
    - notes ::
      + debug symbol :: special kind of symbol that attaches additional information to the symbol table of an object file, such as a shared library or an executable. This information allows a symbolic debugger to gain access to information from the source code of the binary, such as the names of identifiers, including variables and routines
      + object files can contain three kinds of symbols ::
        - defined 'external' symbols, sometimes called "public" or "entry" symbols, which allow it to be called by other modules,
        - undefined 'external' symbols, which reference other modules where these symbols are defined,
        - local symbols, used internally within the object file to facilitate relocation (assigning load addresses for position-dependent code and data of a program and adjusting the code and data to reflect the assigned addresses)
      + the linker also takes care of arranging the objects in a program's address space. This may involve relocating code that assumes a specific base address into another base. Since a compiler seldom knows where an object will reside, it often assumes a fixed base location (for example, zero). Relocating machine code may involve re-targeting absolute jumps, loads, and stores.
      + the executable output by the linker may need another relocation pass when it is finally loaded into memory (just before execution)
      + for most compilers, object files are the results of compiling an input source code file. When a program comprises multiple object files, the linker combines these files into a unified executable program, resolving the symbols as it goes along.
      + linkers can take objects from a library or runtime library.
      + most linkers do not include *all* the object files in a static library in the output executable; they include only those object files from the library that are referenced by other object files or libraries directly or indirectly.
        - static libraries :: set of routines, external functions and variables which are resolved in a caller at *compile-time* and copied into a target application by a compiler, linker, or binder, producing an object file and a stand-alone executable.
      + for a shared library, the entire library has to be loaded during runtime as it is not known which functions or methods will be called during runtime
      + the term 'loader' is usually used to describe the process of loading external symbols from other programs during the process of linking
      + GNU linker :: (or GNU ld, with 'ld' is usually used to refer to a linker) is the GNU Project's implementation of the Unix command ld. GNU ld runs the linker, which creates an executable file (or a library) from object files. A linker script may be passed to GNU ld to exercise greater control over the linking process. GNU ld is part of the GNU Binary Utilities (binutils). Two versions of ld are provided in binutils: the traditional GNU ld based on bfd, and a 'streamlined' ELF-only version called ==gold== linker. The command-line and linker script syntaxes of GNU ld is the de facto standard in much of the Unix-like world. The LLVM (set of compiler and toolchain technologies that can be used to develop a frontend for any programming language and a backend for any instruction set architecture (ISA)) project's linker, ==lld==, is designed to be drop-in compatible, and may be used directly with the GNU compiler. Another drop-in replacement, ==mold==, is a highly parallelized and faster alternative which is also supported by GNU tools.
        - ==g++== and ==gcc== are ==drivers==. Usually, they run the preprocessor (cpp), compiler proper (cc1plus for C++ and cc1 for C) and the linker (gold or GNU ld) and all other things necessary. The difference between gcc and g++ is that the latter includes one additional library to link against (libstdc++). Depending on what type of file they are invoked on, they may omit some steps or do things differently. For object files for example, it doesn't need to run the compiler proper or the preprocessor. If one passes ==-###== to them, it prints the tools it invokes in each step of its execution.
    - dynamic linking :: many OS environments allow dynamic linking, deferring the resolution of some undefined symbols until a program is run. That means that the executable code still contains undefined symbols, plus a list of objects or libraries that will provide definitions for these. Loading the program will load these objects/libraries as well, and perform a final linking.
      + advantages :: 1. often-used libraries (eg: the standard system libraries) need to be stored in only one location, not duplicated in every single executable file, thus saving limited memory and disk space; 2. if a bug in a library function is corrected by replacing the library or performance is improved, all programs using it dynamically will benefit from the correction after restarting them. Programs that included this function by static linking would have to be re-linked first.
      + disadvantages :: 1. 'dll hell' on windows: an incompatible updated library will break executables that depended on the behavior of the previous version of the library if the newer version is not correctly backward compatible; 2. a program, together with the libraries it uses, might be certified (e.g. as to correctness, documentation requirements, or performance) as a package, but not if components can be replaced (this also argues against automatic OS updates in critical systems; in both cases, the OS and libraries form part of a qualified environment).
    - static linking :: result of the linker copying all library routines used in the program into the executable image. May require more disk space and memory than dynamic linking, but is more portable, since does not require the presence of the library on the system where it runs. Also prevents 'DLL hell', since each program includes exactly the versions of library routines that it requires, with no conflict with other programs. Programs using just a few routines from a library do not require the entire library to be installed.
    - relocation :: the compiler has no information on the layout of objects in the final output, it cannot take advantage of shorter or more efficient instructions that place a requirement on the address of another object. For example, jump instructions can reference an absolute address or an offset from the current location, and the offset could be expressed with different lengths depending on the distance to the target. By first generating the most conservative instruction (usually the largest relative or absolute variant, depending on platform) and adding relaxation hints, it is possible to substitute shorter or more efficient instructions during the final link. In regard to jump optimizations this is also called automatic jump-sizing. This step can be performed only after all input objects have been read and assigned temporary addresses; the linker relaxation pass then reassigns addresses, which may in turn allow more potential relaxations to occur. In general, the substituted sequences are shorter, which allows this process to always converge on the best solution given a fixed order of objects; if this is not the case, relaxations can conflict, and the linker needs to weigh the advantages of either option. While instruction relaxation typically occurs at link-time, inner-module relaxation can already take place as part of the optimizing process at compile-time. 
  + gcc flags ::
    - -E :: stop after the preprocessing stage; do not run the compiler proper
    - -S :: stop after the stage of compilation proper; do not assemble
    - -c :: compile or assemble, but do not link
    - -o <file> :: place output in <file>. Applies regardless to whatever sort of output being produced: executable file, object file, assembler file or preprocessed C code. If -o is not specified, the default is to put an executable file in a.out
- x64 assembly code uses sixteen 64-bit registers. Additionally, the lower bytes of some of these registers may be accessed independently as 32-, 16- or 8-bit registers
- memory management ::
  + top of memory reserved for use by the OS.
  + global variables are stored in the ==data== section of the memory. Unlike the stack, the data region does not grow or shrink, storage space for global variables persists for the entire run of the program.
  + the heap portion of memory is the part of a program’s address space associated with dynamic memory allocation. The heap is typically located far from stack memory, and grows into higher addresses as more space is dynamically allocated by the running program.
  + local variables and parameters reside on the stack. Stack grows as the program calls functions, and shrinks on return from function. Stacks is typically allocated near the bottom of memory (highest memory addresses).
- memory addresses on the stack :: when quadword is split into words for example, the stack can be seen as a stack addresses of words: given a quadword ~fedcba9876543210~, on a word stack it becomes: ~fe;dc;ba;98;76;54;32;10~, with ~fe~ (the most significant byte) to the *lowest address* available on the stack (the top of the stack %rsp, %esp in this case since it's a word stack) minus the size of the word register, and ~10~ (the least significant byte) at the top of the stack. Can be seen as a reversed storage, with the beginning of the element at the bottom. Reminder: The current available stack memory goes from highest addresses (starting point), to lowest as the stack is growing. So when the stack is "growing" the %rsp address is actually decreasing.
** vocabulary
:PROPERTIES:
:CUSTOM_ID: vocab
:END:
- "byte" :: a one-byte integer (suffix ==b==, for signed/unsigned char for example)
- "word" :: a two-byte integer (suffix ==w==, for signed/unsigned short)
- "doubleword" :: a four-byte integer (suffix ==l==, for signed/unsigned int)
- "quadword" :: eight-byte value (suffix ==q==, for signed/unsigned long)
** x64 assembly registers
[2024-04-05 Fri 22:02]
- assembly registers :: sixteen 64-bit registers in x86-64:
  +---------------+---------+---------+------+
  |8-byte register|Bytes 0-3|Bytes 0-1|Byte 0|
  +---------------+---------+---------+------+
  |%rax           |%eax     |%ax      |%al   |
  |%rcx           |%ecx     |%cx      |%cl   |
  |%rdx           |%edx     |%dx      |%dl   |
  |%rbx           |%ebx     |%bx      |%bl   |
  |%rsi           |%esi     |%si      |%sil  |
  |%rdi           |%edi     |%di      |%dil  |
  |%rsp           |%esp     |%sp      |%spl  |
  |%rbp           |%ebp     |%bp      |%bpl  |
  |%r8            |%r8d     |%r8w     |%r8b  |
  |%r9            |%r9d     |%r9w     |%r9b  |
  |%r10           |%r10d    |%r10w    |%r10b |
  |%r11           |%r11d    |%r11w    |%r11b |
  |%r12           |%r12d    |%r12w    |%r12b |
  |%r13           |%r13d    |%r13w    |%r13b |
  |%r14           |%r14d    |%r14w    |%r14b |
  |%r15           |%r15d    |%r15w    |%r15b |
  +---------------+---------+---------+------+
- register usage :: sixteen 64-bit registers in x86-64: %rax, %rbx, %rcx, %rdx, %rdi, %rsi, %rbp, %rsp, and %r8-r15
  + %rsp :: (r 'stack pointer')) used as the stack pointer, a pointer to the topmost element in the stack, the starting point of the current context
  + %rax, %rcx, %rdx, %rdi, %rsi, %rsp, and %r8-r11 :: are ==caller-save== registers, meaning that they are not necessarily saved across function calls
    - %rax :: by convention, is used to store a function’s return value, if it exists and is no more than 64 bits long (Larger return types like structs are returned using the stack.)
  + %rbx, %rbp, and %r12-r15 :: are ==callee-save== registers, meaning that they are saved across function calls
  + %rbp :: (r 'base pointer') in 32-bit x86, the base pointer (formerly %ebp, now %rbp) was used to keep track of the base of the current stack frame, and a called function would save the base pointer of its caller prior to updating the base pointer to its own stack frame.
    - with the advent of the 64-bit architecture, this has been mostly eliminated, save for a few special cases when the compiler cannot determine ahead of time how much stack space needs to be allocated for a particular function (see Dynamic stack allocation)
  + %rdi, %rsi, %rdx, %rcx, %r8, and %r9 :: are used to pass the first six integer or pointer parameters to called functions. Additional parameters (or large parameters such as structs passed by value) are passed on the stack
- register sizes :: eg: %rax: 8 bytes (quadword: 64 bits); %eax: 4 bytes (doubleword: 32 bits); %ax: 2 bytes (word: 16 bits); %ah and %al: 1 byte, with %ah the 4 most significant bits, and %al the 4 least significant bits.
  + %ah and %al are part of the same byte %ax, just that when for example requesting %ah the operation is done on the highest part of %ax
** Some assembly instructions
[2024-04-05 Fri 22:01]
- introduction ::
  + some basic types of operand specifiers ::
    +---------+------------------+----------------------------+--------------+
    |Type     |From              |Operand Value               |Name          |
    +---------+------------------+----------------------------+--------------+
    |Immediate|$Imm              |Imm                         |Immediate     |
    |Register |E_{a}             |R[E_{a}]                    |Register      |
    |Memory   |Imm               |M[Imm]                      |Absolute      |
    |Memory   |(E_{a})           |M[R[E_{a}]]                 |Absolute      |
    |Memory   |Imm(E_{b},E_{i},s)|M[Imm+R[E_{b}]+(R[E_{i}]xs)]|Scaled indexed|
    +---------+------------------+----------------------------+--------------+
  + legend ::
    - Imm :: constant value, e.g. 0x8048d8e or 48,
    - E_{x} :: a register, e.g. %rax,
    - R[E_{x}] :: value stored in register E_{x},
    - M[x] :: value stored at memory address x
- notes ::
  + most instructions, like ==mov==, use a suffix to show how large the operands are going to be (checkout [[#vocab][vocabulary]])
    - eg: ~movq %rax, %rbx~: move quadword from %rax to %rbx
  + others, such as ==movs== and ==movz== will use two suffixes, as they convert operands of the type of the first suffix to that of the second
    - eg: to convert the byte in %al to a doubleword in %ebx with zero-extension would be ~movzbl %al, %ebx~
*** Data movement
- instructions with one suffix ::
  + reminder :: the stack grows from high addresses (bottom, since the address "0" is the memory's "start"), *to lowest*, so, a "push" is really a ~sub %rsp, 8; movq [%rsp], D~, and a "pop" is a ~movq D, [%rsp]; add %rsp, 8~ => the %rsp address actually decreases as its memory increases. It's better to see the stack as a reversed field of addresses
  + mov S, D :: move source to destination
    - depends on assembler's syntax, eg with x64 intel syntax: ~mov m, rax~: move contents of rax to 64-bit address)
    - most UNIX assemblers including the GNU assembler uses AT&T syntax (~mov src, dest~), and others x86 assemblers use intel syntax
  + push S :: push source onto stack (on the top of the current stack)
  + pop D :: pop top of stack into destination
- instructions with two suffixes ::
  + mov S, D :: move byte to word (sign extended)
  + push S :: move byte to word (zero extended)
- instructions with no suffixes ::
  + cwtl :: convert word in %ax to doubleword in %eax (sign-extended)
  + cltq :: convert doubleword in %eax to quadword in %rax (sign-extended)
  + cqto :: convert quadword in %rax to octoword in %rdx:%rax
*** Arithmetic operations
[2024-04-06 Sat 02:10]
- unless otherwise specified, all arithmetic operation instructions have one suffix
- unary operations :: ~inc D~ (increment by 1) ~dec D; neg D~ (arithmetic negation); ~not D~ (bitwise complement)
- binary operations :: ~leaq S, D~ (load effective address of source into destination); ~add S, D; sub S, D; imul S, D~ (multiply destination by source, and put result in the destination, so for example with intel syntax: ~imul dest, src~: signed multiplication of two operands, and put result in ==dest==); ~xor S, D~ (bitwise XOR destination by source); ~or S, D; and S, D~
- shift operations :: ~sal / shl k, D~ (left shift destination by k bits); ~sar k, D~ (arithmetic right shift destination by k bits); ~shr k, D~ (logical right shift destination by k bits)
- special arithmetic operations ::
  + imulq S :: signed full multiply of %rax by S; result stored in %rdx:%rax
  + mulq S :: unsigned full multiply of %rax by S;
  + idivq S :: signed divide %rdx:%rax by S; quotient stored in %rax; remainder stored in %rdx
  + divq S :: unsigned divide %rdx:%rax by S
*** Comparison and Test Instructions
[2024-04-06 Sat 02:24]
- comparison instructions also have one suffix
- cmp S2, S1 :: set condition codes according to S1 - S2
- test S2, S1 :: set condition codes according to S1 & S2
*** Accessing Condition Codes
[2024-04-06 Sat 02:27]
- not any suffix
- conditional set instructions ::
  + sete/setz D :: set if equal/zero; ==ZF== (condition code, or "assembly status flag registry" for zero flag)
    - setne/setnz D :: set if not equal/nonzero; ==~ZF==
  + sets D :: set if negative; ==SF== (SF flag for "sign flag")
    - setns D :: set if nonnegative; ==~SF==
  + setg/setnle D :: set if greater (signed); ==~(SF^0F)&~ZF== (0F for overflow flag, when overflow occurred; ^ for xor operator)
  + setge/setnl D :: set if greater or equal (signed); ==~(SF^0F)==
  + setl/setnge D :: set if less (signed); ==SF^0F==; jumps if SF != OF
  + setle/setng D :: set if less or equal; ==(SF^OF)|ZF==
  + seta/setnbe D :: set if above (unsigned); ==~CF&~ZF== (CF for carry flag occurring when arithmetic carry or borrow has been generated out of the most significant arithmetic logic unit (ALU) bit position)
  + setae/setnb D :: set if above or equal (unsigned); ==~CF==
  + setb/setnae D :: set if below (unsigned); ==CF==
  + setbe/setna D :: set if below or equal (unsigned); ==CF|ZF==
- jump instructions ::
  + jmp Label :: jump to label
  + jmp *Operand :: jump to specified location
  + je/jz Label :: jump if equal/zero ==ZF==
  + jne/jnz Label :: jump if not equal/nonzero ==~ZF==
  + js Label :: jump if negative ==SF==
  + jns Label :: jump if nonnegative ==~SF==
  + jg/jnle Label :: jump if greater (signed) ==~(SF^0F)&~ZF==
  + jge/jnl Label :: jump if greater or equal (signed) ==~(SF^0F)==
  + jl/jnge Label :: jump if less (signed) ==SF^0F==
  + jle/jng Label :: jump if less or equal ==(SF^OF)|ZF==
  + ja/jnbe Label :: jump if above (unsigned) ==~CF&~ZF==
  + jae/jnb Label :: jump if above or equal (unsigned) ==~CF==
  + jb/jnae Label :: jump if below (unsigned) ==CF==
  + jbe/jna Label :: jump if below or equal (unsigned) ==CF|ZF==
- conditional move instructions ::
  + conditional move instructions do not have any suffixes, but their source and destination operands *must have* the same size
  + cmove/cmovz S, D :: move if equal/zero ==ZF==
  + cmovne/cmovnz S, D :: move if not equal/nonzero ==~ZF==
  + cmovs S, D :: move if negative ==SF==
  + cmovns S, D :: move if nonnegative ==~SF==
  + cmovg/cmovnle S, D :: move if greater (signed) ==~(SF^0F)&~ZF==
  + cmovge/cmovnl S, D :: move if greater or equal (signed) ==~(SF^0F)==
  + cmovl/cmovnge S, D :: move if less (signed) ==SF^0F==
  + cmovle/cmovng S, D :: move if less or equal ==(SF^OF)|ZF==
  + cmova/cmovnbe S, D :: move if above (unsigned) ==~CF&~ZF==
  + cmovae/cmovnb S, D :: move if above or equal (unsigned) ==~CF==
  + cmovb/cmovnae S, D :: move if below (unsigned) ==CF==
  + cmovbe/cmovna S, D :: move if below or equal (unsigned) ==CF|ZF==
*** Procedure Call Instruction
[2024-04-06 Sat 03:51]
- procedure call instructions do not have any suffixes
- call Label :: push return address and jump to label
- call *Operand :: push return address and jump to specified location
- leave :: set %rsp to %rbp, then pop top of stack into %rbp
- ret :: pop return address from stack and jump there
** Arrays
[2024-04-05 Fri 22:03]
- arrays are stored in memory as contiguous blocks of data, with pointer to first element
- eg: arr[i] = 3, can be expressed in x86-64 as (assuming the address of arr is stored in %rax and the index i is stored in %rcx): ~movq $3, (%rax, %rcx, 8)~
** Stack Organization and Function Calls
[2024-04-06 Sat 04:03]
*** Calling a Function
- to call a function, the program should place the first six integer or pointer parameters in the registers %rdi, %rsi, %rdx, %rcx, %r8, and %r9
- subsequent parameters (or parameters larger than 64 bits) should be pushed onto the stack, with the first argument topmost
- the program should then execute the call instruction, which will push the return address onto the stack and jump to the start of the specified function
- if the function has a return value, it will be stored in %rax after the function call
- eg:
  #+begin_src asm
  # Call foo(1, 15)
  movq $1, %rdi # Move 1 into %rdi
  movq $15, %rsi # Move 15 into %rsi
  call foo # Push return address and jump to label foo
  #+end_src
*** Writing a function
- uses the stack to support function calls
- the top of the stack grows towards lower memory addresses
- for each function call, new space is created on the stack to store local variables and other data (this is known as a "stack frame")
- set up :: "function prologue"
  + when a call instruction is executed, the address of the following *instruction* is pushed onto the stack as the return address and control passes to the specified function
  + if the function is going to use any of the callee-save registers (%rbx, %rbp, or %r12-r15), the current value of each should be pushed onto the stack to be restored at the end, eg:
    #+begin_src asm
    pushq %rbx
    pushq %r12
    pushq %r13
    #+end_src
  + additional space may be allocated on the stack for local variables. Though it's possible to make space on the stack as needed in a function body, it is generally more efficient to allocate this space all at once at the beginning of the function.
    - This can be accomplished using the call ~subq $N, %rsp~ where N is the size of the callee’s stack frame. eg: ~subq $0x18, %rsp # to allocate 24 bytes of space on the stack~
- using the stack frame :: once the stack frame is set up, it's possible to use it to store and access local variables:
  + arguments which cannot fit in registers (e.g. structs) will be pushed onto the stack before the call instruction, and can be accessed relative to %rsp. Keep in mind that it's required to take the size of the stack frame into account when referencing arguments in this manner
  + if the function has more than six integer or pointer arguments, these will be pushed onto the stack as well
  + for any stack arguments, the lower-numbered arguments will be closer to the stack pointer. That is, arguments are pushed on in right-to-left order when applicable
  + local variables will be stored in the space allocated in the function prologue, when some amount is subtracted from %rsp. The organization of these is up to the programmer
- clean up ::
  + after the body of the function is finished and the return value (if any) is placed in %rax, the function must return control to the caller, putting the stack back in the state in which it was called with:
    - first :: the callee frees the stack space it allocated by adding the same amount to the stack pointer, eg: ~addq $0x18, %rsp # give back the 24 bytes of stack space used in previous example with 'subq $0x18, %rsp'~
    - then :: it pops off the registers it saved earlier
      #+begin_src asm
      popq %r13 # stack is FILO, and in previous 'set up' example, did last: 'pushq %r13'
      popq %r12
      popq %rbx
      #+end_src
    - finally :: the program should return to the call site, using the ~ret~ instruction
- summary ::all previous put together, the code for a function should look like this:
  #+begin_src asm
  foo:
         # set up
         pushq %rbx # Save registers, if needed <=> save the calling function’s stack frame pointer (rbp register)
         pushq %r12
         pushq %r13
         subq $0x18, %rsp # Allocate stack space
         # Function body ...
         # Clean up
         addq $0x18, %rsp # Deallocate stack space
         popq %r13 # Restore registers
         popq %r12
         popq %rbx ret # Pop return address and return control to caller
  #+end_src
*** Dynamic stack allocation
[2024-04-06 Sat 04:59]
- notes ::
  + static stack space is usually not enough, in this case, use a trick from 32-bit x86, and save the base of the stack frame into the base pointer register
  + since %rbp is a callee-save register, it needs to be saved before it is changed, and the function prologue is then prefixed with: ~pushq %rbp; movq %rsp, %rbp~
  + consequently, the epilogue will contain the following, before ==ret==: ~movq %rbp, %rsp; popq %rbp~
  + this can also be done in the single instruction: ==leave==
  + the epilogue makes sure that no matter what one does to the stack pointer in the function body, he will always return it to the right place when he returns/leaves. Note that this means that there is no longer need to add to the stack pointer in the epilogue
  + eg: function which allocates between 8-248 bytes of random stack space during its execution:
    #+begin_src asm
    pushq %rbp # Use base pointer/push %rbp to stack/Saves registers, if needed <=> save the calling function’s stack frame pointer (rbp register)
    movq %rsp, %rbp
    pushq %rbx # Save registers
    pushq %r12
    subq $0x18, %rsp # Allocate some stack space
    ...
    call rand # Get random number
    andq $0xF8, %rax # Make sure the value is 8-248 bytes and
    # aligned on 8 bytes
    subq %rax, %rsp # Allocate space
    …
    movq (%rbp), %r12 # Restore registers from base of frame
    movq 0x8(%rbp), %rbx
    movq %rbp, %rsp # Reset stack pointer and restore base
    # pointer
    popq %rbp ret
    #+end_src
  + eg 2:
    #+begin_src asm
    push    rbp       ; Save the calling function’s stack frame pointer (rbp register)
    mov     rbp, rsp  ; Copy value of rsp into rbp. Make a new stack frame below our caller’s stack
    sub     rsp, 32   ; Reserve 32 bytes of stack space for this function’s local variables.
                      ; Local variables will be below rbp and can be referenced relative to rbp,
                      ; again best for ease of debugging, but for best performance rbp will not
                      ; be used at all, and local variables would be referenced relative to rsp
                      ; because, apart from the code saving, rbp then is free for other uses.
     …       …        ; However, if rbp is altered here, its value should be preserved for the caller.
    mov [rbp-8], rdx  ; Example of accessing a local variable, from memory location into register rdx
    #+end_src
** More examples
[2024-04-07 Sun 21:26]
- loops ::
  + source code ::
    #+begin_src cpp
    int test(int a, unsigned int b) {
    
        int buff = a - b;
        for (; b>0; --b) {
            a += b;
        }
        if (buff < 0) {
            return 0;
        }
        return a;
    }
    
    int loop(int a, unsigned int b) {
        for (; b>0; --b) {
            a += b;
        }
        return a;
    }
    int caller() {
        int i = loop(1,3);
        if (i < 10) {
            return i;
        }
        return 10;
    }
    #+end_src
  + assembly ::
    #+begin_src asm
    test(int, unsigned int):
            push    rbp
            mov     rbp, rsp
            mov     DWORD PTR [rbp-20], edi
            mov     DWORD PTR [rbp-24], esi
            mov     eax, DWORD PTR [rbp-20]
            sub     eax, DWORD PTR [rbp-24]
            mov     DWORD PTR [rbp-4], eax
            jmp     .L2
    .L3:
            mov     edx, DWORD PTR [rbp-20]
            mov     eax, DWORD PTR [rbp-24]
            add     eax, edx
            mov     DWORD PTR [rbp-20], eax
            sub     DWORD PTR [rbp-24], 1
    .L2:
            cmp     DWORD PTR [rbp-24], 0
            jne     .L3
            cmp     DWORD PTR [rbp-4], 0
            jns     .L4
            mov     eax, 0
            jmp     .L5
    .L4:
            mov     eax, DWORD PTR [rbp-20]
    .L5:
            pop     rbp
            ret

    loop(int, unsigned int):
            push    rbp
            mov     rbp, rsp
            mov     DWORD PTR [rbp-4], edi ; load int argument into the stack => under the base pointer rbp (-4 for int size of 4)
            mov     DWORD PTR [rbp-8], esi
            jmp     .L2
    .L3:
            mov     edx, DWORD PTR [rbp-4]
            mov     eax, DWORD PTR [rbp-8]
            add     eax, edx
            mov     DWORD PTR [rbp-4], eax
            sub     DWORD PTR [rbp-8], 1
    .L2:
            cmp     DWORD PTR [rbp-8], 0
            jne     .L3
            mov     eax, DWORD PTR [rbp-4]
            pop     rbp
            ret

    caller():
            push    rbp
            mov     rbp, rsp
            sub     rsp, 16
            mov     esi, 3
            mov     edi, 1
            call    loop(int, unsigned int)
            mov     DWORD PTR [rbp-4], eax
            cmp     DWORD PTR [rbp-4], 9
            jg      .L6
            mov     eax, DWORD PTR [rbp-4]
            jmp     .L7
    .L6:
            mov     eax, 10
    .L7:
            leave
            ret
    __static_initialization_and_destruction_0(int, int):
            push    rbp
            mov     rbp, rsp
            sub     rsp, 16
            mov     DWORD PTR [rbp-4], edi
            mov     DWORD PTR [rbp-8], esi
            cmp     DWORD PTR [rbp-4], 1
            jne     .L10
            cmp     DWORD PTR [rbp-8], 65535
            jne     .L10
            mov     edi, OFFSET FLAT:_ZStL8__ioinit
            call    std::ios_base::Init::Init() [complete object constructor]
            mov     edx, OFFSET FLAT:__dso_handle
            mov     esi, OFFSET FLAT:_ZStL8__ioinit
            mov     edi, OFFSET FLAT:_ZNSt8ios_base4InitD1Ev
            call    __cxa_atexit
    .L10:
            nop
            leave
            ret
    _GLOBAL__sub_I_loop(int, unsigned int):
            push    rbp
            mov     rbp, rsp
            mov     esi, 65535
            mov     edi, 1
            call    __static_initialization_and_destruction_0(int, int)
            pop     rbp
            ret
    #+end_src
  
* Best practices
* Glossary
  - programming :: writing program that creates, transforms, filters, aggregates and otherwise manipulates data.
  - Metaprogramming :: writing a program that creates, transforms, filters, aggregates and otherwise manipulates *programs*.
  - Generic programming :: writing a program that creates, transforms, filters, aggregates and otherwise manipulates data, but makes only the minimum assumptions about the structure of the data, thus maximizing reuse across a wide range of datatypes.
  - Note on difference between metaprogramming and generic programming ::
    + generic Programming and (static/compile time) metaprogramming are both done with Templates
    + plus, generic programming uses Metaprogramming to be efficient, i.e. Template Specialization generates specialized (fast) programs from generic ones.
* CMAKE
* Unit testing
